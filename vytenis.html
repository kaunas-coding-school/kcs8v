<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Vytenis</title>
    <link rel="stylesheet" href="CSS/reset.css">
    <link rel="stylesheet" href="CSS/vytenis.css">
</head>
<body>
<div class="meniu">
    <div class="button_sliding_backg">
<a href="Evaldas.html">Evaldas</a>
<a href="tautvydas.html">Tautvydas</a>
<a href="paulius.html">Paulius</a>
<a href="Gytis.html">Gytis</a>
<a href="vytenis.html">Vytenis</a>
<a href="mantas.html">Mantas</a>
<a href="Rytis.html">Rytis</a>
<a href="andrius.html">Andrius</a>
</div>
</div>
<hr>
<div class="turinys">
    <img src="img/mano_foto.jpg" alt="Vytenis" class="profilio_foto"/>
    <h1>Vytenis</h1>
    <hr/>
    Lorem ipsum dolor sit amet, consectetur adipiscing elit.
    Fusce eu venenatis ante. Nam dictum ante nec tortor dapibus,
    sed fermentum dolor interdum. Vivamus tempus massa sem,
    id vehicula orci semper eget. Pellentesque habitant morbi
    tristique senectus et netus et malesuada fames ac turpis egestas.
    Pellentesque fringilla, mauris in tempus semper, diam lorem posuere nunc,
    vel accumsan nulla ante in arcu. Praesent in hendrerit augue, in fermentum
    sem. Morbi diam est, laoreet in facilisis ornare, imperdiet sit amet urna.
    Duis ultricies nisi ac lectus mattis, in dictum turpis feugiat. Curabitur
    feugiat tempor massa porttitor porttitor. Maecenas sed fringilla odio.
    Sed mattis aliquet pellentesque. In posuere ac sem sed auctor.
    In sem quam, eleifend ac lacus id, tincidunt convallis justo.
    Integer sed tempus nunc, eget imperdiet nisi. In hac habitasse platea
    dictumst. Aenean ac tellus id diam interdum finibus in ac ipsum.
    Recent progress on image captioning has made it possible to generate novel
    sentences describing images in natural language, but compressing an image
    into a single sentence can describe visual content in only coarse detail.
    While one new captioning approach, dense captioning, can potentially describe
    images in finer levels of detail by captioning many regions within an image,
    it in turn is unable to produce a coherent story for an image. In this paper
    we overcome these limitations by generating entire paragraphs for describing
    images, which can tell detailed, unified stories. We develop a model that
    decomposes both images and paragraphs into their constituent parts, detecting
    semantic regions in images and using a hierarchical recurrent neural network
    to reason about language. Linguistic analysis confirms the complexity of the
    paragraph generation task, and thorough experiments on a new dataset of image
    and paragraph pairs demonstrate the effectiveness of our approach.

</div>
<hr/>
<footer>2017â’¸</footer>
<body class="backg" background="img/juodas.jpg"><body/>
</body>
</html>